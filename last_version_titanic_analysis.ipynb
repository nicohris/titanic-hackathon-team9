{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hippolyte\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "c:\\Users\\Hippolyte\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrandom\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m seed\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mrn\u001b[39;00m\n\u001b[0;32m      6\u001b[0m seed_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2509\u001b[39m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from numpy.random import seed\n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "seed_value=2509\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "rn.seed(seed_value)\n",
    "from sklearn import preprocessing                            \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold,StratifiedKFold,train_test_split \n",
    "import matplotlib.pyplot as plt\n",
    "from keras import models\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('/data/train.csv')\n",
    "test = pd.read_csv('/data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "combo = [train, test]\n",
    "for item in combo:\n",
    "    item['Sex'] = item['Sex'].map( {'male': 1, 'female': 0} ).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for item in combo:\n",
    "    item['FamilySize'] = item['SibSp'] + item['Parch']+1 \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Let's examine how the size of a family affected survival , size of 1 means travelling alone\n",
    "train[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for item in combo:\n",
    "    item.loc[(item['FamilySize'] ==1) , 'Fsize'] = 0\n",
    "    item.loc[(item['FamilySize'] ==2) , 'Fsize'] = 1\n",
    "    item.loc[(item['FamilySize'] ==3) , 'Fsize'] = 2\n",
    "    item.loc[(item['FamilySize'] ==4) , 'Fsize'] = 3\n",
    "    item.loc[(item['FamilySize'] >4) , 'Fsize'] = 4\n",
    "    item['Fsize']=item['Fsize'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for item in combo:\n",
    "    item['Title'] = item.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "    # We do not need Name feature anymore\n",
    "    item = item.drop(['Name'], axis=1, inplace=True)\n",
    "\n",
    "print(\"Titles in test dataset\")\n",
    "print(' ')\n",
    "print(test.Title.unique())\n",
    "print(' ')\n",
    "print(\"Titles in train dataset\")\n",
    "print(' ')\n",
    "print(train.Title.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for item in combo:\n",
    "    item['Title'] = item['Title'].replace(['Ms','Lady', 'Countess','Dona'],'Mrs')\n",
    "    item['Title'] = item['Title'].replace(['Mme','Mlle'], 'Miss')\n",
    "    item['Title'] = item['Title'].replace(['Major', 'Sir', 'Jonkheer', 'Dr','Col','Don', 'Capt','Rev'],'Mr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Oups , passenger 797 is a woman titled Dr. so we have to change category to 'Mrs'\n",
    "print(train.loc[(train.PassengerId== 797) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"#############  Test dataset titles ###############\")\n",
    "print(train.Title.value_counts())\n",
    "print(\"#############  Train dataset titles ###############\")\n",
    "print(test.Title.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Let's extract the first letters from cabins\n",
    "for item in combo:\n",
    "    item['Cabin'].fillna('N', inplace=True)\n",
    "    item['Cabin'] = item['Cabin'].map(lambda c: c[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# If we examine all first letters from both sets we see a type T,it is category A as we will analyse below, so we replace it.\n",
    "print('Train set Cabin names',train.Cabin.unique())\n",
    "print('Test set Cabin names',test.Cabin.unique())\n",
    "train['Cabin'] = train['Cabin'].replace(['T'], 'A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sns.barplot(x=\"Cabin\", y=\"Survived\", data=train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for item in combo:\n",
    "    item['Cabin'] = item['Cabin'].replace(['A', 'B','C',\"D\",'E','T'], 0)\n",
    "    item['Cabin'] = item['Cabin'].replace(['F','G'], 0)\n",
    "    item['Cabin'] = item['Cabin'].replace(['N'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    " train[['Cabin','Survived']].groupby(['Cabin'], as_index=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train['Embarked'] = train['Embarked'].fillna('S')\n",
    "combo = [train, test]\n",
    "for item in combo:\n",
    "    item['Embarked'] = item['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "combo = [train, test]\n",
    "for item in combo:\n",
    "# We replace missing ages by the mean age of passengers who belong to the same group of class/sex/family\n",
    " item['Age'] = item.groupby(['Pclass','Title'])['Age'].apply(lambda x: x.fillna(x.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#complete missing fare with median\n",
    "test['Fare'].fillna(test['Fare'].median(), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train['FareBin'] = pd.qcut(train['Fare'], 10)\n",
    "train[['FareBin','Survived']].groupby(['FareBin'], as_index=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for item in combo:\n",
    "    item.loc[ item['Fare'] <= 7.55, 'Fare'] = 0\n",
    "    item.loc[(item['Fare'] > 7.55) & (item['Fare'] <= 10.5), 'Fare'] = 1\n",
    "    item.loc[(item['Fare'] > 10.5) & (item['Fare'] <= 14.454), 'Fare'] = 2\n",
    "    item.loc[(item['Fare'] > 14.454) & (item['Fare'] <= 21.67), 'Fare']   = 3\n",
    "    item.loc[(item['Fare'] > 21.67) & (item['Fare'] <= 77.958), 'Fare']   = 4\n",
    "    item.loc[ item['Fare'] > 77.958, 'Fare'] = 5\n",
    "    item['Fare'] = item['Fare'].astype(int)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    " train[['Pclass','Survived']].groupby(['Pclass'], as_index=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    " train[['Fare','Survived']].groupby(['Fare'], as_index=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for item in combo:\n",
    "   item = item.drop(['Ticket'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Explore Age vs Survived\n",
    "g = sns.FacetGrid(train, col='Survived', height=4, aspect=1, sharex='none')\n",
    "g = g.map(sns.distplot, \"Age\", bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train['Age2']=-1\n",
    "test['Age2']=-1\n",
    "\n",
    "combo=[train,test]\n",
    "for item in combo:\n",
    "    item.loc[(item['Age'] <=4), 'Age2'] =0\n",
    "    item.loc[(item['Age']<=17 )& (item['Age'] >4), 'Age2'] =1\n",
    "    item.loc[(item['Age'] >=18) & (item['Age'] <=32), 'Age2'] =2\n",
    "    item.loc[(item['Age'] >32) & (item['Age'] <=42), 'Age2']= 3\n",
    "    item.loc[(item['Age'] >42) & (item['Age'] <=52), 'Age2']= 4\n",
    "    item.loc[(item['Age'] >52) & (item['Age'] <=60), 'Age2']= 5\n",
    "    item.loc[(item['Age'] >60) , 'Age2']= 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    " train[['Survived','Age2']].groupby(['Age2'], as_index=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sns.barplot( x=\"Age2\",y=\"Survived\", data=train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "\n",
    "pearson_coef1 , p_value1 =scipy.stats.pearsonr(train[\"Cabin\"],train[\"Pclass\"])\n",
    "print (\"Cabin - Pclass\", pearson_coef1,\"    Correlation certainty =\",p_value1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sns.factorplot('Pclass','Survived',hue='Sex',data=train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for item in combo:\n",
    "    item = item.drop(['Sex'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for item in combo:\n",
    "    item.loc[((item['Title']=='Miss') & (item['Age'] <=4)), 'Title'] = 'child'\n",
    "    item.loc[((item['Title']=='Master') & (item['Age'] <=4)), 'Title'] = 'child'\n",
    "    item.loc[((item['Title']=='Miss') & (item['Age'] <=17)), 'Title'] = 'kid'\n",
    "    item.loc[((item['Title']=='Master') & (item['Age'] <=17)), 'Title'] = 'kid'\n",
    "    item.loc[((item['Title']=='Master') & (item['Age'] >17)), 'Title'] = 'Mr'\n",
    "    item.loc[((item['Title']=='Mrs') & (item['Parch']!=0)),'Title']='MrsYesCh'\n",
    "    item.loc[((item['Title']=='Mrs') & (item['Parch']==0)),'Title']='MrsNoCh'\n",
    "    item = item.drop(['SibSp','Parch'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train['Title'] = train['Title'].map({ 'Mr': 0 ,'Miss':1, 'MrsNoCh':2 ,'MrsYesCh':3,'kid':4,'child':5}).astype(int)\n",
    "test['Title'] = test['Title'].map({'Mr': 0 ,'Miss':1, 'MrsNoCh':2 ,'MrsYesCh':3,'kid':4, 'child':5}).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sns.barplot( x=\"Embarked\",y=\"Survived\", data=train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for item in combo:\n",
    "    item = item.drop(['Age'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#set up the data for the models\n",
    "X_train = train.drop(['Survived','PassengerId','FamilySize','FareBin'], axis=1)\n",
    "col=(X_train.columns)\n",
    "Y_train = train[\"Survived\"]\n",
    "X_test=test.drop([\"PassengerId\",\"FamilySize\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()  \n",
    "scaler.fit_transform(X_train)\n",
    "scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2,f_classif\n",
    "from numpy import set_printoptions\n",
    "\n",
    "test1 = SelectKBest(score_func= f_classif, k=4)\n",
    "fit = test1.fit(X_train, Y_train)\n",
    "set_printoptions(precision=3)\n",
    "print(col)\n",
    "print('       ',fit.scores_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top three most important features are Title, Pclass and Fare "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "# feature extraction\n",
    "model = ExtraTreesClassifier(n_estimators=10)\n",
    "model.fit(X_train, Y_train)\n",
    "print(col)\n",
    "print('Feature importance')\n",
    "print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import shap \n",
    "shap.initjs() \n",
    "dmatrix=xgb.DMatrix(X_train, label=Y_train)\n",
    "model = xgb.train({\"learning_rate\": 0.01}, dmatrix, 100)\n",
    "model_bytearray = model.save_raw()[4:]\n",
    "\n",
    "def myfun(self=None):\n",
    "    return model_bytearray\n",
    "\n",
    "model.save_raw = myfun\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "shap.summary_plot(shap_values, X_train, plot_type=\"bar\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "rfe = RFE(estimator=DecisionTreeClassifier(), n_features_to_select=4)\n",
    "fit = rfe.fit(X_train, Y_train)\n",
    "print('Features :  ',col)\n",
    "print(\"Num Features: \",fit.n_features_)\n",
    "print(\"Selected Features: \",fit.support_)\n",
    "print(\"Feature Ranking: \",fit.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_train = pd.get_dummies(X_train, columns = [\"Title\"],prefix=\"N\")\n",
    "X_train = pd.get_dummies(X_train, columns = [\"Fare\"],prefix=\"F\",drop_first=True)\n",
    "X_test = pd.get_dummies(X_test, columns = [\"Title\"],prefix=\"N\")\n",
    "X_test = pd.get_dummies(X_test, columns = [\"Fare\"],prefix=\"F\",drop_first=True)\n",
    "Y_train = train[\"Survived\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_train.drop([\"Embarked\",\"Cabin\",'Age2'], axis=1, inplace=True)\n",
    "\n",
    "X_test.drop([\"Embarked\",\"Cabin\",'Age2'], axis=1,inplace=True)\n",
    "\n",
    "print(\"Training set X: \", X_train.shape, \"Training set Y:\",Y_train.shape, \"Testing set X\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sns.heatmap(X_train.corr(), cmap='viridis',annot = True)\n",
    "fig=plt.gcf()\n",
    "fig.set_size_inches(10,8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier,AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import VotingClassifier, StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import keras\n",
    "from keras import models,layers,optimizers\n",
    "from keras.optimizers import Adam \n",
    "from keras.layers import Activation, Dense ,Dropout \n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from numpy import mean , std\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from numpy import arange, argmax\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.metrics import auc,confusion_matrix,classification_report,roc_curve,accuracy_score,roc_auc_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "randomforest = RandomForestClassifier(criterion = 'gini',bootstrap= True, max_depth= 5, max_features=10,  min_samples_split= 31, n_estimators=20,random_state=seed_value)\n",
    "svc_model = SVC(C=0.5, cache_size=200, \n",
    "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf', max_iter=-1, probability=True, random_state=seed_value, shrinking=True, tol=0.001,verbose=False)\n",
    "knn = KNeighborsClassifier(leaf_size= 6,n_neighbors = 16, p=1 ,weights = 'uniform') \n",
    "modellt =  LGBMClassifier(boosting_type='gbdt',num_leaves = 31,max_depth =5,learning_rate =0.05,subsample= 1,colsample_bytree = 0.8, reg_lambda =0.5,reg_alpha=                          0.5,\n",
    "                          n_estimators=500,objective='binary',metric='binary_logloss', seed=seed_value)\n",
    "#check xgb\n",
    "xgb_model=XGBClassifier( alpha =0.5, colsample_bytree =0.8 ,gamma=0.5,learning_rate= 0.1, max_depth= 5,n_estimators=100,\n",
    "                         objective= 'binary:logistic',subsample= 0.8, random_state=seed_value)\n",
    "modelM=MLPClassifier(hidden_layer_sizes=(16,8,1),activation='tanh',solver='adam', alpha=0.01, batch_size=32, learning_rate='adaptive', learning_rate_init=0.001, max_iter=850, shuffle=False, random_state=seed_value, tol=0.001, verbose=False,early_stopping=False,validation_fraction=0.3, beta_1=0.9, beta_2=0.999, epsilon=1e-08 )\n",
    "AdaB=AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=5),learning_rate=0.001,n_estimators=100,random_state=seed_value)\n",
    "gb = GradientBoostingClassifier(criterion='mae',n_estimators=150,learning_rate = 0.1,max_features=7,max_depth =3, \n",
    "            min_samples_leaf=3, min_samples_split= 32, subsample= 1,random_state=seed_value)\n",
    "\n",
    "\n",
    "NN1=('NN', modelM)\n",
    "XG1=('XGboost', xgb_model)\n",
    "GR1=('GradientB',gb)\n",
    "SVM1= ('SVM',svc_model)\n",
    "ADA1=('Ada',AdaB)\n",
    "KNN1=('KNN',knn)\n",
    "RF1=('RF',randomforest)\n",
    "LG1=('LightGBM',modellt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model):\n",
    "    seed=7\n",
    "    kfld = StratifiedKFold(n_splits=5,shuffle=True,random_state=seed)\n",
    "    scores = cross_val_score(model, X_train , Y_train, scoring='accuracy', cv=kfld, n_jobs=-1, error_score='raise')\n",
    "    return scores\n",
    "\n",
    "clfs={'LightGBM':[modellt,78.707],'XGBoost':[xgb_model,99978.229],'GradientBoost':[gb,78.468]\n",
    "            ,'AdaBoost':[AdaB,78.229],'RandomForest':[randomforest,78.707],\n",
    "            'SVM':[svc_model,78.229],'KNN':[knn,80.143],'MLP':[modelM,79.168]}\n",
    "scores={}\n",
    "for name, model in clfs.items():\n",
    "    metr=evaluate_model(model[0])\n",
    "    scores.update({name:[mean(metr),std(metr),model[1]]})\n",
    "\n",
    "results_table = pd.DataFrame(scores, index=['Mean_accuracy', 'Std', 'Leaderboard']).round(decimals=3)\n",
    "results_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "def plot_learning_curve(estimator, title, X, y):\n",
    " \n",
    "    train_sizes, train_scores, test_scores = learning_curve(estimator, X, y , cv=10, n_jobs=-1,train_sizes=np.linspace(.1, 1.0, 5),random_state = 2509)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    \n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"b\", label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"orange\",  label=\"Cross-validation score\")\n",
    "    \n",
    "    # Plot learning curve\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                         train_scores_mean + train_scores_std, alpha=0.1,color=\"b\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                         test_scores_mean + test_scores_std, alpha=0.1, color=\"orange\")\n",
    "    \n",
    "models_set={'LightGBM':modellt,'XGBoost':xgb_model,'GradientBoost':gb,'AdaBoost':AdaB,\n",
    "            'RandomForest':randomforest,'SVM':svc_model,'KNN':knn,'MLP':modelM}\n",
    "\n",
    "ax=0\n",
    "plt.figure(figsize = (25,25))\n",
    "plt.suptitle(\"Models Learning Curves\", fontsize = 28)\n",
    "\n",
    "for name, model in models_set.items():\n",
    "     ax+=1\n",
    "     plt.subplot(4,2,ax)\n",
    "     plt.title(name, fontsize = 18)\n",
    "     plot_learning_curve(model,name,X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X_train, Y_train, test_size=0.2,shuffle=True ,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_roc_curve\n",
    "\n",
    "classifiers = [knn,randomforest, modelM, modellt,xgb_model,gb,svc_model,AdaB]\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "ax = plt.gca()\n",
    "for clf in classifiers:\n",
    "     model = clf.fit(x_train, y_train)\n",
    "     plot_roc_curve(model, x_test, y_test, ax=ax)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score,f1_score,average_precision_score\n",
    "def evaluation(name,clf):\n",
    "    model=clf.fit(x_train,y_train)\n",
    "    y_prob = model.predict_proba(x_test)[:, 1]\n",
    "    prAuc = average_precision_score(y_test, y_prob)\n",
    "    y_pred = model.predict(x_test)\n",
    "    acc = balanced_accuracy_score(y_test, y_pred)\n",
    "    f1= f1_score(y_test, y_pred)\n",
    "    return prAuc,acc,f1     \n",
    " \n",
    "scores={}\n",
    "for name, model in models_set.items():\n",
    "    metr=evaluation(name,model)\n",
    "    scores.update({name:[metr[0],metr[1],metr[2]]})\n",
    "results = (pd.DataFrame(scores, index=['PR-AUC','Balanced_Accuracy','F1 score'])).round(decimals=3)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def clf_predictions(model):\n",
    "    model.fit(X_train, Y_train)\n",
    "    ypredict = model.predict(X_test)\n",
    "    return ypredict\n",
    "\n",
    "predictions = {name: clf_predictions(model) for name, model in models_set.items()}\n",
    "estimations = pd.DataFrame(predictions) \n",
    "sns.heatmap(estimations.corr(),cmap='viridis', annot = True)\n",
    "fig=plt.gcf()\n",
    "fig.set_size_inches(10,8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# function to create classifiers using Voting or Stacking\n",
    "def create_clf(E,t):\n",
    "    if t=='Voting':    \n",
    "        vclf=VotingClassifier(E, voting='hard')\n",
    "    else:\n",
    "        vclf=StackingClassifier(E, final_estimator= LogisticRegression())\n",
    "    return vclf\n",
    "\n",
    "#Step1 \n",
    "E1=[KNN1,NN1,SVM1,RF1,GR1]\n",
    "#Step2 \n",
    "E2=[KNN1,SVM1,RF1,GR1]\n",
    "#Step3 \n",
    "E3=[KNN1,SVM1,GR1] \n",
    "#Step4 \n",
    "E4=[KNN1,SVM1]\n",
    "\n",
    "ensembles_set={'KNN-NN-SVM-RF-GR':[E1,'79.186','78.947'],'KNN-SVM-RF-GR':[E2,'79.425','79.186 ']\n",
    "             ,'KNN-SVM-GR':[E3,'79.425','79.186'],'KNN-SVM1':[E4,'80.382','78.468']}\n",
    "scores1={}\n",
    "scores2={}\n",
    "for clf, item in ensembles_set.items():\n",
    "    newclv=create_clf(item[0],'Voting')\n",
    "    newclST=create_clf(item[0],'Stacking')\n",
    "    kfoldevalv=evaluate_model(newclv)\n",
    "    kfoldevalst=evaluate_model(newclST)\n",
    "    scores1.update({clf:[mean(kfoldevalv),std(kfoldevalv),item[1]]})\n",
    "    scores2.update({clf:[mean(kfoldevalst),std(kfoldevalst),item[2]]})\n",
    "results1 = pd.DataFrame(scores1, index=['Mean_accuracy', 'Std','Leaderboard'])\n",
    "results2 = pd.DataFrame(scores2, index=['Mean_accuracy', 'Std','Leaderboard'])\n",
    "print('VOTING CLASSIFIERS')\n",
    "display(results1)\n",
    "print('STACKING CLASSIFIERS')\n",
    "display(results2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "E=[KNN1,SVM1]\n",
    "vot=VotingClassifier(E, voting='hard')\n",
    "ensemble = vot.fit(X_train, Y_train) \n",
    "y_vote = ensemble.predict(X_test)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "            \"PassengerId\": test[\"PassengerId\"],\n",
    "            \"Survived\": y_vote\n",
    "    })\n",
    "submission.to_csv('Titanic.csv', index=False)\n",
    "print(\"Your submission was successfully saved!\") \n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 26502,
     "sourceId": 3136,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 29994,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
